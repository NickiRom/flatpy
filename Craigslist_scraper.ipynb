{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = \"nickirom\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from urlparse import urljoin\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "\n",
    "\n",
    "#CURRENT_TIME = time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "CURRENT_TIME = datetime.now()\n",
    "BATCH_MIN_TIME = CURRENT_TIME - timedelta(hours=1)\n",
    "\n",
    "MAX_WAIT = 3\n",
    "\n",
    "BASE_URL = 'http://sfbay.craigslist.org/search/sfc/roo?s=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_all_listings(url):\n",
    "    run_again = 1\n",
    "    all_apts = []\n",
    "\n",
    "    while run_again == 1:\n",
    "        apts, run_again, url = get_listings(url, run_again)\n",
    "        all_apts.extend(apts)\n",
    "    \n",
    "    return all_apts\n",
    "        \n",
    "def scrape_all_apts(listings):\n",
    "    apt_data = []\n",
    "    for apt in listings:\n",
    "        link = apt.find('a').attrs['href']\n",
    "\n",
    "        # join this relative link with the\n",
    "        # BASE_URL to create an absolute link\n",
    "        url = urljoin(BASE_URL, link)\n",
    "\n",
    "        apt_data.append(scrape_apt(url)[1])\n",
    "        \n",
    "    return apt_data\n",
    "\n",
    "def get_listings(url, run_again):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content.decode('utf-8', 'ignore'))\n",
    "    apts = soup.find_all('span', {'class':'pl'})\n",
    "\n",
    "    min_time = datetime.strptime(min([item.time.attrs['datetime'] for item in apts]), \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    if min_time < BATCH_MIN_TIME:\n",
    "        run_again = 0\n",
    "        apts = [apt for apt in apts if datetime.strptime(apt.time.attrs['datetime'], \"%Y-%m-%d %H:%M\") >= BATCH_MIN_TIME]\n",
    "\n",
    "    else: \n",
    "        start_num = str(int(re.findall('\\?s=(.+)', url)[0]) + 100)\n",
    "        url = re.findall('(.+)\\?s=', url)[0] + \"?s=\" + start_num\n",
    "    \n",
    "    time.sleep(MAX_WAIT*random.random())\n",
    "\n",
    "    return apts, run_again, url\n",
    "\n",
    "def scrape_apt(url):\n",
    "    \"\"\" Extract information from a apt page. \"\"\"\n",
    "\n",
    "    print \"scraping url %s\" %str(url)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the html of the  post\n",
    "    soup = BeautifulSoup(response.content.decode('utf-8', 'ignore'))\n",
    "\n",
    "    # Extract the actual contents of some HTML elements:\n",
    "    \n",
    "    data = {\n",
    "        'source_url': url,\n",
    "        'subject': None,\n",
    "        'price':  None,\n",
    "        'neighborhood': None,\n",
    "        'sqft': None,\n",
    "        'tags': [],\n",
    "        'images': [],\n",
    "        'geo': None,\n",
    "        'body': ''\n",
    "    }\n",
    "    \n",
    "    try: data['subject'] = get_data(soup.find('h2', {'class':'postingtitle'}).find('span', {'id':'titletextonly'}), 'subject')\n",
    "    except: data['subject'] = None\n",
    "        \n",
    "    try: data['price'] = get_data(soup.find('span', {'class': 'price'}), 'price')\n",
    "    except: data['price'] = None\n",
    "\n",
    "    try: data['neighborhood'] = neighborhood(get_data(soup.find('small'), 'neighborhood').strip())\n",
    "    except: data['neighborhood'] = None\n",
    "    \n",
    "    try: data['sqft'] = sqft(get_data(soup.find('span', {'class': 'housing'}), 'sqft'))\n",
    "    except: pass\n",
    "    \n",
    "    try: data['tags'] = tags(soup('p', {'class':'attrgroup'})[1])\n",
    "    except: pass\n",
    "    \n",
    "    try: data['images'] = get_images(soup)\n",
    "    except: pass\n",
    "    \n",
    "    try: data['geo'] = get_geo(soup),\n",
    "    except: pass\n",
    "    \n",
    "    try: data['body']= get_data(soup.find('section', {'id':'postingbody'}), 'body')\n",
    "    \n",
    "        # Print it prettily.\n",
    "        #pprint([data[key] for key in data.keys() if key != 'body'])\n",
    "    \n",
    "    except UnicodeEncodeError as e:\n",
    "        print url\n",
    "        print \"Unicode Error: \", e\n",
    "        data = url\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print url\n",
    "        print \"AttributeError! : \", e\n",
    "        data = e\n",
    "    else:\n",
    "        print sys.exc_info()[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    time.sleep(MAX_WAIT*random.random())\n",
    "    \n",
    "    return soup, data\n",
    "\n",
    "def get_data(action, name):\n",
    "    try:\n",
    "        result = action\n",
    "        return result.get_text()\n",
    "    except AttributeError as e:\n",
    "        print \"Error getting data\"\n",
    "        print \"Action was: %s\" %str(name)\n",
    "        return None\n",
    "\n",
    "def subject(action):\n",
    "    print str(action)\n",
    "    \n",
    "def price(action):\n",
    "    print str(action)\n",
    "    \n",
    "def tags(action):\n",
    "    try:\n",
    "        tags =[p.text for p in action if len(p)>0]\n",
    "        return tags\n",
    "    except AttributeError:\n",
    "        print \"tag AttributeError\"\n",
    "        return None\n",
    "    \n",
    "def price(text):\n",
    "    try:\n",
    "        price = int(re.search('\\$\\s*([0-9]+)', text).groups()[0])\n",
    "    except AttributeError:\n",
    "        print \"pricing AttributeError\"\n",
    "        price = None\n",
    "    except TypeError:\n",
    "        print \"price data DNE\"\n",
    "        price = None\n",
    "    return price\n",
    "    \n",
    "def sqft(text):\n",
    "    try:\n",
    "        sqft = int(re.search('\\/\\s*([0-9]+)', text).groups()[0])   \n",
    "    except AttributeError:\n",
    "        print \"sqft AttributeError\"\n",
    "        sqft= None\n",
    "    except TypeError:\n",
    "        print \"sqft data DNE\"\n",
    "        sqft= None\n",
    "    return sqft\n",
    "\n",
    "def neighborhood(text):\n",
    "    try:\n",
    "        hood = re.search('\\s*\\(\\s*(.*)\\s*\\)\\s*', text).groups()[0]   \n",
    "    except AttributeError:\n",
    "        print \"neighborhood AttributeError\"\n",
    "        hood= None\n",
    "    except TypeError:\n",
    "        print \"neighborhood data DNE\"\n",
    "        hood= None\n",
    "    return hood\n",
    "\n",
    "def get_images(soup):\n",
    "    \n",
    "    try:\n",
    "        #check for thumbnails due to multiple images:\n",
    "        urls =[thumb.find('img')['src'] for thumb in soup.find('div', {'id':'thumbs'})]\n",
    "    except:\n",
    "        try:\n",
    "            urls = [get_data(soup.find('div', {'class': 'slide first visible'}).find('img')['src'], 'image')]\n",
    "        except:\n",
    "            urls = None\n",
    "    return urls\n",
    "\n",
    "def get_geo(soup):\n",
    "    #check for thumbnails due to multiple images:\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'mapbox'}).find('div', {'class':'viewposting'})\n",
    "        geo = {'lat':div['data-latitude'], 'lon':div['data-longitude']}\n",
    "    except:\n",
    "        geo= None\n",
    "    return geo\n",
    "\n",
    "def room_dimensions(body):\n",
    "    try: \n",
    "        dims = [int(dim) for dim in re.match(\".*[\\s|\\(]{1}([0-9]{2})[']*[\\s]*[x]\\s*([0-9]{2})[']*[\\s|\\)]{1}.*\", body).groups()]\n",
    "        return dims\n",
    "    except AttributeError:\n",
    "        print \"room_dimensions AttributeError\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(url):\n",
    "\n",
    "    listings = get_all_listings(url)\n",
    "    print \"listings have been retrieved\"\n",
    "    \n",
    "    apt_data = scrape_all_apts(listings)\n",
    "    \n",
    "    return apt_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listings have been retrieved\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5492851443.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "Error getting data\n",
      "Action was: image\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500712315.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494310057.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494458355.html\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494465513.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494397090.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494396002.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494308149.html\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5484285255.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494319319.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494307302.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494331478.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494354857.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494364056.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500707165.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "Error getting data\n",
      "Action was: image\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500706311.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500702311.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500701874.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5485831774.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494363143.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494358597.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494362241.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494454662.html\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5494360168.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500694775.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500691167.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5491371982.html\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5496142924.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5461203385.html\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500683478.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5484490039.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500636506.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500678491.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5497587903.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500672051.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500669550.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500644948.html\n",
      "Error getting data\n",
      "Action was: sqft\n",
      "sqft data DNE\n",
      "None\n",
      "scraping url http://sfbay.craigslist.org/sfc/roo/5500664424.html\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "apt_data = run(BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for apt in apt_data:\n",
    "    print [(key,apt[key]) for key in apt.keys() if key !='body']\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://sfbay.craigslist.org/sfc/roo/5472543000.html'\n",
    "response = requests.get(url)\n",
    "print url \n",
    "print response\n",
    "\n",
    "soup = BeautifulSoup(response.content.decode('utf-8', 'ignore'))\n",
    "#print [thumb.find('img')['src'] for thumb in soup.find('div', {'id':'thumbs'})]\n",
    "#print get_data(soup.find('span', {'class': 'price'}), 'price')\n",
    "print sqft(get_data(soup.find('span', {'class': 'housing'}), 'sqft'))\n",
    "price(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(apt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>geo</th>\n",
       "      <th>images</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>price</th>\n",
       "      <th>source_url</th>\n",
       "      <th>sqft</th>\n",
       "      <th>subject</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nHuge, amazing apartment on Union St right ne...</td>\n",
       "      <td>({u'lat': u'37.796879', u'lon': u'-122.437138'},)</td>\n",
       "      <td>[None]</td>\n",
       "      <td>marina / cow hollow</td>\n",
       "      <td>$1750</td>\n",
       "      <td>http://sfbay.craigslist.org/sfc/roo/5492851443...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great Deal! Furnished Amazing Apt on Union</td>\n",
       "      <td>[furnished, no smoking, private room, private ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nRoom available ASAP.\\n\\nHi, my name is Guido...</td>\n",
       "      <td>({u'lat': u'37.713210', u'lon': u'-122.404990'},)</td>\n",
       "      <td>[http://images.craigslist.org/00808_czHZfoh7JC...</td>\n",
       "      <td>visitacion valley</td>\n",
       "      <td>$1000</td>\n",
       "      <td>http://sfbay.craigslist.org/sfc/roo/5500712315...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 bedroom in 2br apt</td>\n",
       "      <td>[no smoking, private room, no private bath, w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nLocated in the highly desired SOMA area, bet...</td>\n",
       "      <td>({u'lat': u'37.777726', u'lon': u'-122.409072'},)</td>\n",
       "      <td>[http://images.craigslist.org/00E0E_cS2ZIgvJpB...</td>\n",
       "      <td>SOMA / south beach</td>\n",
       "      <td>$900</td>\n",
       "      <td>http://sfbay.craigslist.org/sfc/roo/5494310057...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazing Shared Room, Mission District</td>\n",
       "      <td>[furnished, no smoking, room not private, no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n1010 Bush Street, San Francisco -- Balmoral ...</td>\n",
       "      <td>({u'lat': u'37.789509', u'lon': u'-122.413888'},)</td>\n",
       "      <td>[http://images.craigslist.org/00p0p_iIpczMcRsD...</td>\n",
       "      <td>financial district</td>\n",
       "      <td>$1795</td>\n",
       "      <td>http://sfbay.craigslist.org/sfc/roo/5494458355...</td>\n",
       "      <td>108</td>\n",
       "      <td>Private Rooms, Great Location</td>\n",
       "      <td>[furnished, no smoking, room not private, no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nLocated in the highly desired SOMA area - co...</td>\n",
       "      <td>({u'lat': u'37.777100', u'lon': u'-122.407394'},)</td>\n",
       "      <td>[http://images.craigslist.org/00f0f_3E6N5oQvla...</td>\n",
       "      <td>mission district</td>\n",
       "      <td>$650</td>\n",
       "      <td>http://sfbay.craigslist.org/sfc/roo/5494465513...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUAD available in dorm style accommodation</td>\n",
       "      <td>[furnished, room not private, no private bath,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  \\nHuge, amazing apartment on Union St right ne...   \n",
       "1  \\nRoom available ASAP.\\n\\nHi, my name is Guido...   \n",
       "2  \\nLocated in the highly desired SOMA area, bet...   \n",
       "3  \\n1010 Bush Street, San Francisco -- Balmoral ...   \n",
       "4  \\nLocated in the highly desired SOMA area - co...   \n",
       "\n",
       "                                                 geo  \\\n",
       "0  ({u'lat': u'37.796879', u'lon': u'-122.437138'},)   \n",
       "1  ({u'lat': u'37.713210', u'lon': u'-122.404990'},)   \n",
       "2  ({u'lat': u'37.777726', u'lon': u'-122.409072'},)   \n",
       "3  ({u'lat': u'37.789509', u'lon': u'-122.413888'},)   \n",
       "4  ({u'lat': u'37.777100', u'lon': u'-122.407394'},)   \n",
       "\n",
       "                                              images         neighborhood  \\\n",
       "0                                             [None]  marina / cow hollow   \n",
       "1  [http://images.craigslist.org/00808_czHZfoh7JC...    visitacion valley   \n",
       "2  [http://images.craigslist.org/00E0E_cS2ZIgvJpB...   SOMA / south beach   \n",
       "3  [http://images.craigslist.org/00p0p_iIpczMcRsD...   financial district   \n",
       "4  [http://images.craigslist.org/00f0f_3E6N5oQvla...     mission district   \n",
       "\n",
       "   price                                         source_url  sqft  \\\n",
       "0  $1750  http://sfbay.craigslist.org/sfc/roo/5492851443...   NaN   \n",
       "1  $1000  http://sfbay.craigslist.org/sfc/roo/5500712315...   NaN   \n",
       "2   $900  http://sfbay.craigslist.org/sfc/roo/5494310057...   NaN   \n",
       "3  $1795  http://sfbay.craigslist.org/sfc/roo/5494458355...   108   \n",
       "4   $650  http://sfbay.craigslist.org/sfc/roo/5494465513...   NaN   \n",
       "\n",
       "                                      subject  \\\n",
       "0  Great Deal! Furnished Amazing Apt on Union   \n",
       "1                        1 bedroom in 2br apt   \n",
       "2       Amazing Shared Room, Mission District   \n",
       "3               Private Rooms, Great Location   \n",
       "4  QUAD available in dorm style accommodation   \n",
       "\n",
       "                                                tags  \n",
       "0  [furnished, no smoking, private room, private ...  \n",
       "1  [no smoking, private room, no private bath, w/...  \n",
       "2  [furnished, no smoking, room not private, no p...  \n",
       "3  [furnished, no smoking, room not private, no p...  \n",
       "4  [furnished, room not private, no private bath,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n",
      "room_dimensions AttributeError\n"
     ]
    }
   ],
   "source": [
    "df['room_dimensions'] = df['body'].apply(lambda x: room_dimensions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "room_dimensions(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
